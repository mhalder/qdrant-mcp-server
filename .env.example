# Qdrant Configuration
QDRANT_URL=http://localhost:6333

# ============================================================================
# Embedding Provider Configuration
# ============================================================================
# Choose your embedding provider: openai, cohere, voyage, ollama
# Default: ollama (no API key required, works out of the box)
EMBEDDING_PROVIDER=ollama

# ============================================================================
# Ollama Configuration (Local/Self-hosted) - DEFAULT
# ============================================================================
# No API key required! Just start Ollama and pull a model:
#   docker compose up -d
#   docker exec ollama ollama pull nomic-embed-text

EMBEDDING_BASE_URL=http://localhost:11434

# Optional: Override defaults
# EMBEDDING_MODEL=nomic-embed-text
# EMBEDDING_DIMENSIONS=768
# EMBEDDING_MAX_REQUESTS_PER_MINUTE=1000
# EMBEDDING_RETRY_ATTEMPTS=3
# EMBEDDING_RETRY_DELAY=500

# Available Ollama models (depends on what you have pulled):
# - nomic-embed-text (768 dimensions) - recommended
# - mxbai-embed-large (1024 dimensions)
# - all-minilm (384 dimensions)
# Run `docker exec ollama ollama pull <model-name>` to download models

# ============================================================================
# OpenAI Configuration (Alternative Provider)
# ============================================================================
# Uncomment to use OpenAI instead of Ollama:
# EMBEDDING_PROVIDER=openai
# OPENAI_API_KEY=sk-your-api-key-here

# Optional: Override defaults
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_DIMENSIONS=1536
# EMBEDDING_MAX_REQUESTS_PER_MINUTE=3500
# EMBEDDING_RETRY_ATTEMPTS=3
# EMBEDDING_RETRY_DELAY=1000

# ============================================================================
# Cohere Configuration
# ============================================================================
# EMBEDDING_PROVIDER=cohere
# COHERE_API_KEY=your-cohere-api-key-here

# Optional: Override defaults
# EMBEDDING_MODEL=embed-english-v3.0
# EMBEDDING_DIMENSIONS=1024
# EMBEDDING_MAX_REQUESTS_PER_MINUTE=100
# EMBEDDING_RETRY_ATTEMPTS=3
# EMBEDDING_RETRY_DELAY=1000

# Available Cohere models:
# - embed-english-v3.0 (1024 dimensions)
# - embed-multilingual-v3.0 (1024 dimensions)
# - embed-english-light-v3.0 (384 dimensions)
# - embed-multilingual-light-v3.0 (384 dimensions)

# ============================================================================
# Voyage AI Configuration
# ============================================================================
# EMBEDDING_PROVIDER=voyage
# VOYAGE_API_KEY=your-voyage-api-key-here

# Optional: Override defaults
# EMBEDDING_MODEL=voyage-2
# EMBEDDING_DIMENSIONS=1024
# EMBEDDING_BASE_URL=https://api.voyageai.com/v1
# EMBEDDING_MAX_REQUESTS_PER_MINUTE=300
# EMBEDDING_RETRY_ATTEMPTS=3
# EMBEDDING_RETRY_DELAY=1000

# Available Voyage models:
# - voyage-2 (1024 dimensions)
# - voyage-large-2 (1536 dimensions)
# - voyage-code-2 (1536 dimensions)
# - voyage-lite-02-instruct (1024 dimensions)

# ============================================================================
# Ollama Configuration (Local/Self-hosted)
# ============================================================================
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_BASE_URL=http://localhost:11434

# Optional: Override defaults
# EMBEDDING_MODEL=nomic-embed-text
# EMBEDDING_DIMENSIONS=768
# EMBEDDING_MAX_REQUESTS_PER_MINUTE=1000
# EMBEDDING_RETRY_ATTEMPTS=3
# EMBEDDING_RETRY_DELAY=500

# Available Ollama models (depends on what you have pulled):
# - nomic-embed-text (768 dimensions)
# - mxbai-embed-large (1024 dimensions)
# - all-minilm (384 dimensions)
# Run `ollama pull <model-name>` to download models

# ============================================================================
# Notes
# ============================================================================
# - For OpenAI, Cohere, and Voyage: API key is required
# - For Ollama: No API key needed (local deployment)
# - EMBEDDING_MODEL, EMBEDDING_DIMENSIONS, and rate limit configs are optional
# - Each provider has sensible defaults if not specified
